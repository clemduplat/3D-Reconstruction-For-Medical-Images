{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spinetools\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "root_directory = None\n",
    "view_0 = 'PA0'\n",
    "view_1 = 'LAT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "Please write the RMS calculation function here. You will need this function throughout the assignment, so craft it with care !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rms(reference: np.ndarray, prediction: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates RMS\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reference : np.ndarray\n",
    "        Reference value\n",
    "    prediction : np.ndarray\n",
    "        Calculated/predicted value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        RMS metric\n",
    "    \"\"\"\n",
    "    if reference.shape != prediction.shape:\n",
    "        raise ValueError('Please provide arrays that are shaped the same! Reference has shape {refshape} whereas prediction has shape {predshape}'.format(refshape=reference.shape, predshape=prediction.shape))\n",
    "\n",
    "    # For 2D arrays (N, 3) where we calculate RMS for each axis (X, Y, Z)\n",
    "    if len(reference.shape) == 2 and reference.shape[1] == 3:\n",
    "        rms_value = np.sqrt(np.mean(np.sum((reference - prediction) ** 2, axis=1)))\n",
    "    \n",
    "    # For 1D arrays (N, ) where we calculate a single RMS value\n",
    "    elif len(reference.shape) == 1:\n",
    "        rms_value = np.sqrt(np.mean((reference - prediction) ** 2))\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid array shape. Expected (N,) or (N, 3), got {}'.format(reference.shape))\n",
    "\n",
    "    return rms_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D RMS: 0.6324555320336759\n",
      "2D RMS: 0.816496580927726\n"
     ]
    }
   ],
   "source": [
    "# 1D\n",
    "reference_1d = np.array([1, 2, 3, 4, 5])\n",
    "prediction_1d = np.array([2, 2, 3, 4, 6])\n",
    "\n",
    "# Manually calculating the RMS for this simple case:\n",
    "# Difference = [1, 0, 0, 0, 1]\n",
    "# Squared difference = [1, 0, 0, 0, 1]\n",
    "# Mean of squared differences = (1+0+0+0+1)/5 = 0.4\n",
    "# RMS = sqrt(0.4) = 0.6324555320336759\n",
    "\n",
    "print(\"1D RMS:\", rms(reference_1d, prediction_1d))  # Expected: 0.6324555320336759\n",
    "# 2D Test Case: 2D arrays where each row is (x, y, z) coordinate\n",
    "reference_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "prediction_2d = np.array([[1, 2, 3], [4, 4, 6], [8, 8, 9]])\n",
    "\n",
    "# Manually calculating RMS for this case:\n",
    "# For each point:\n",
    "# Point 1 difference: [0, 0, 0]\n",
    "# Point 2 difference: [0, 1, 0]\n",
    "# Point 3 difference: [1, 0, 0]\n",
    "# Squared differences: [0, 0, 0], [0, 1, 0], [1, 0, 0]\n",
    "# Sum of squared differences for each point: [0, 1, 1]\n",
    "# Mean of the sums: (0 + 1 + 1) / 3 = 0.6667\n",
    "# RMS = sqrt(0.6667) = 0.816496580927726\n",
    "\n",
    "print(\"2D RMS:\", rms(reference_2d, prediction_2d))  # Expected: 0.816496580927726\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.1\n",
    "Write the code for finding the over determined system matrix A. Then use the dlt function from spinetools.solver to extract the L parameters vector for each view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped A_4_1\n",
      "Dropped B_3_5\n"
     ]
    }
   ],
   "source": [
    "root_directory = \"Datafiles_LAB1/\"\n",
    "beads_data = spinetools.io.process_files(root_directory)\n",
    "# ? Filter out non redundant beads\n",
    "unique_beads = beads_data['2d']['bead'].tolist()\n",
    "unique_beads = [x.replace('C', 'A') for x in unique_beads]\n",
    "unique_beads = [x.replace('D', 'B') for x in unique_beads]\n",
    "\n",
    "# ? Count values\n",
    "value_count = {}\n",
    "for k in unique_beads:\n",
    "    if k in value_count.keys():\n",
    "        value_count[k] += 1\n",
    "    else:\n",
    "        value_count[k] = 1\n",
    "\n",
    "# ? Exclude the ones that aren't visible from everywhere\n",
    "for k, v in zip(list(value_count.keys()), list(value_count.values())):\n",
    "    if v == 1:\n",
    "        print('Dropped', k)\n",
    "        del value_count[k]\n",
    "\n",
    "unique_beads = list(value_count.keys())\n",
    "unique_beads.extend([x.replace('A', 'C') if 'A' in x else x.replace('B', 'D') for x in unique_beads])\n",
    "beads_data['2d'] = beads_data['2d'][beads_data['2d']['bead'].isin(unique_beads)]\n",
    "beads_data['3d'] = beads_data['3d'][beads_data['3d']['bead'].isin(unique_beads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spinetools.data import select_view, join_dataframes\n",
    "\n",
    "def get_a(view:str, data:dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Uses the view name and existing data for pre calculating the system matrix for calculating the 11 DLT coefficients\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    view : str\n",
    "        View name\n",
    "    data : dict\n",
    "        Data as a dict, with two keys ['2d', '3d']. Each key is associated to a table giving points location in 2d/3d, bead identifier and view name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A matrix, for the DLT\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    joint_data = join_dataframes(select_view(data['2d'], view), data['3d'], 'bead')\n",
    "    print(joint_data.columns)\n",
    "\n",
    "    # TODO : Using the equations from Appendix 1, write a function to turn pairs of 2D/3D beads data to an overdeterminated system.\n",
    "    # HINT 1 : we want to end up with some system AM = 0 where M is a vector containing [L0, L1... L10, 1]. So you just need to return A !\n",
    "    # HINT 2 : I gave you 'joint_data'. It's a dataframe, so check the columns names !\n",
    "    for i, row in joint_data.iterrows():\n",
    "        #excract coordinates\n",
    "        X,Y,Z=row[\"x_3d\"], row[\"y_3d\"], row[\"z_3d\"]\n",
    "        u,v=row['x_2d'],row['y_2d']\n",
    "        # !! don't forget constant term to have 11 parameters\n",
    "        row_u = [\n",
    "            X, Y, Z, 1, 0, 0, 0, 0, -u * X, -u * Y, -u * Z,-u\n",
    "        ]\n",
    "        row_v = [\n",
    "            0, 0, 0, 0, X, Y, Z, 1, -v * X, -v * Y, -v * Z,-v\n",
    "        ]\n",
    "        \n",
    "        A.append(row_u)\n",
    "        A.append(row_v)\n",
    "    return np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "l_view0 = spinetools.solver.dlt(get_a('Beads2D_'+view_0, beads_data))\n",
    "l_view1 = spinetools.solver.dlt(get_a('Beads2D_'+view_1, beads_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLT parameters for PA0 :  [ 4.09e-03 -2.57e+00 -2.44e-03 -4.16e-03 -3.60e-02  3.18e-03  2.58e+00\n",
      " -5.67e-01  5.50e-04  1.57e-06 -9.44e-06]\n",
      "DLT parameters for LAT :  [-3.09e+00  1.29e-01 -1.93e-03 -9.36e+02  4.54e-03  4.34e-02  3.10e+00\n",
      "  1.39e+01 -2.36e-05 -6.61e-04 -1.22e-05]\n"
     ]
    }
   ],
   "source": [
    "print(\"DLT parameters for %s : \"%view_0, l_view0)\n",
    "print(\"DLT parameters for %s : \"%view_1, l_view1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View PA0 :\n",
      "\t u0 = -5.818320392632722\n",
      "\t v0 = -145.91496533853473\n",
      "\t c_u = 4667.8104535235125\n",
      "\t c_v = 4684.955368831336\n",
      "\t R = [[ 2.84e-03 -1.00e+00 -9.71e-04]\n",
      " [ 1.72e-02  1.32e-03  1.00e+00]\n",
      " [-1.00e+00 -2.85e-03  1.72e-02]]\n",
      "\t source_coordinates = [ 1.01 -0.    0.55]\n",
      "-------------------------------------------------------------\n",
      "View LAT :\n",
      "\t u0 = -29.21576695254617\n",
      "\t v0 = -152.70327971664815\n",
      "\t c_u = 4673.68335022721\n",
      "\t c_v = 4690.201491353493\n",
      "\t R = [[-9.99e-01  3.56e-02 -7.39e-04]\n",
      " [ 3.04e-04 -1.85e-02  1.00e+00]\n",
      " [ 3.56e-02  9.99e-01  1.85e-02]]\n",
      "\t source_coordinates = [-935.29   32.57  -13.04]\n"
     ]
    }
   ],
   "source": [
    "def get_parameters(dlt_params:np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Outputs a dictionnary containing the intrinsic and extrinsic parameters of the system based on the DLT parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dlt_params : np.ndarray\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dict with keys ['u0', 'v0', 'c_u', 'c_v', 'R', 'source_coordinates']\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    L1, L2, L3, L4, L5, L6, L7, L8, L9, L10, L11 = dlt_params\n",
    "    #\n",
    "    # TODO : Using the equations from Appendix 2, write a function to calculate intrinsic and extrinsic parameters of a system based on the DLT parameters\n",
    "    #----------equations of appendix B----------------#\n",
    "    d = -1/np.sqrt(L9**2 + L10**2 + L11**2) #scaling factor\n",
    "    #intrinsic params\n",
    "    u0 = (L1* L9 + L2 * L10 + L3 * L11) * d**2\n",
    "    v0 = (L5 * L9 + L6 * L10 + L7 * L11) * d**2\n",
    "    #focal lengths\n",
    "    c_u = np.sqrt(d**2 * ((u0 * L9 - L1)**2 + (u0 * L10 - L2)**2 + (u0 * L11 - L3)**2))\n",
    "    c_v = np.sqrt(d**2 * ((v0 * L9 - L5)**2 + (v0 * L10 - L6)**2 + (v0 * L11 - L7)**2))\n",
    "    #Rotation matrix\n",
    "    R = np.array([\n",
    "        [d / c_u * (u0 * L9 - L1), d / c_u * (u0 * L10 - L2), d / c_u * (u0 * L11 - L3)],\n",
    "        [d / c_v * (v0 * L9 - L5), d / c_v * (v0 * L10 - L6), d / c_v * (v0 * L11 - L7)],\n",
    "        [L9 * d, L10 * d, L11 * d]\n",
    "    ])\n",
    "    #source coordinates -R^-1 * T, with T= [L_4,L_8,1]^t the translation vector\n",
    "    source_coordinates = np.linalg.inv(R).dot([-L4, -L8, -1])\n",
    "    out = {'u0': u0,'v0': v0,'c_u': c_u,'c_v': c_v,'R': R,'source_coordinates': source_coordinates}\n",
    "    return out\n",
    "\n",
    "print('View %s :'%view_0)\n",
    "for k, v in get_parameters(l_view0).items():\n",
    "    print('\\t {variable} = {value}'.format(variable = k, value = v))\n",
    "print('-------------------------------------------------------------')\n",
    "print('View %s :'%view_1)\n",
    "for k, v in get_parameters(l_view1).items():\n",
    "    print('\\t {variable} = {value}'.format(variable = k, value = v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_3d_point(u0:float, v0:float, u1:float, v1:float, L0:np.ndarray, L1:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates a 3D point from 2 2D coordinates pairs and L0 & L1 DLT calibration coefficients\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u0 : float\n",
    "        point 1 x-coordinate\n",
    "    v0 : float\n",
    "        point 1 y-coordinate\n",
    "    u1 : float\n",
    "        point 2 x-coordinate\n",
    "    v1 : float\n",
    "        point 2 y-coordinate\n",
    "    L0 : np.ndarray\n",
    "        DLT coefficients for view 1\n",
    "    L1 : np.ndarray\n",
    "        DLT coefficients for view 2\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    # TODO : using Appendix A, write a function that takes 2 pairs of 2D coordinates and 2 11-parameters vectors as an input to return the corresponding 3D point. \n",
    "    # HINT 1 : It's the exact same problem as in question 1.1, but now the unknowns are x,y and z !\n",
    "    # HINT 2 : Refactor the pair of equation in order to have a 4 equations system (2 equations per view, 2 views) for finding a triplet of coordinates : AM = 0 where M = [x, y, z, 1]\n",
    "    \n",
    "    #return spinetools.solver.dlt(np.array(A))\n",
    "    # to solve we need at least 2 sets of projection equations: \n",
    "    \n",
    "    A = [\n",
    "        # PA0 view - u0 equation\n",
    "        [u0 * L0[8] - L0[0], u0 * L0[9] - L0[1], u0 * L0[10] - L0[2], u0 - L0[3]],\n",
    "        # PA0 view - v0 equation\n",
    "        [v0 * L0[8] - L0[4], v0 * L0[9] - L0[5], v0 * L0[10] - L0[6], v0 - L0[7]],\n",
    "        # LAT view - u1 equation\n",
    "        [u1 * L1[8] - L1[0], u1 * L1[9] - L1[1], u1 * L1[10] - L1[2], u1 - L1[3]],\n",
    "        # LAT view - v1 equation\n",
    "        [v1 * L1[8] - L1[4], v1 * L1[9] - L1[5], v1 * L1[10] - L1[6], v1 - L1[7]]\n",
    "    ]\n",
    "    \n",
    "    # Solve the system using DLT \n",
    "    # M will give us [X, Y, Z, 1] -> We are interested in X, Y, Z\n",
    "    M = spinetools.solver.dlt(np.array(A))\n",
    "    \n",
    "    return M[:3]  #x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pio.renderers.default = 'browser'  # Change this if running outside Jupyter\n",
    "\n",
    "# Load the spine structure and the beads data\n",
    "spine = spinetools.structures.Spine(os.path.join(root_directory, 'Vertebrae2D.mat'))\n",
    "colors = px.colors.qualitative.Alphabet\n",
    "fig = spinetools.render.Plot3D()\n",
    "\n",
    "for i, v_name in enumerate(spine.vertebrae):\n",
    "    # TODO : for each vertebra, calculate the location of each anatomical landmark and add its x,y,z coordinates to vert_x, vert_y, vert_z. Each vertebra will then be added to the 3D plot and plotted in the end.\n",
    "    vert = spine.get(v_name).data # Returns the vertebra data\n",
    "    \"\"\"\n",
    "    HINT : the data is a table containing the landmark name and the x,y coordinates for each view (so 5 columns)\n",
    "    HINT : Print the variable vert, and add a 'break' instruction to get out of the loop\n",
    "    For each vertebra, you should have 6 points. Each point is linked to 2 pairs of 2D coordinates, one in each view. These coordinates, with the two 11-DLT parameters will allow you to calculate the 3D position of the 6 anatomical landmarks on the vertebra.\n",
    "    \"\"\"\n",
    "    vert_x, vert_y, vert_z = [], [], []\n",
    "    \"\"\"\n",
    "    PSEUDOCODE\n",
    "    for each anatomical_landmark in vertebra_points:\n",
    "        x_point, y_point, z_point <- calculate_3d_point(anatomical_landmark, l_view0, l_view1)\n",
    "        Append x_point to vert_x\n",
    "        Append y_point to vert_y\n",
    "        Append z_point to vert_z\n",
    "    \"\"\"\n",
    "    # for each anatomical_landmark in vertebra_points\n",
    "    for j, row in vert.iterrows():\n",
    "        # 2D PA0\n",
    "        u0, v0 = row['x_Vertebrae_PA0'], row['y_Vertebrae_PA0']\n",
    "        \n",
    "        # 2D LAT\n",
    "        u1, v1 = row['x_Vertebrae_LAT'], row['y_Vertebrae_LAT']\n",
    "        \n",
    "        # 3D using DLT \n",
    "        x, y, z = calculate_3d_point(u0, v0, u1, v1, l_view0, l_view1)\n",
    "        \n",
    "        vert_x.append(x)\n",
    "        vert_y.append(y)\n",
    "        vert_z.append(z)\n",
    "    \n",
    "    \n",
    "    fig.scatter_vertebrae(vert_x, vert_y, vert_z, v_name, colors[i]) # Adds the landmarks to the figure\n",
    "SPINE_3D_POINTS = fig.points # Access all the figure points as an array this way, will be useful in the rest of this assignment\n",
    "fig.show() # Shows the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I recommend you write a function that samples `n_beads` in the full set, and returns the subset. A code skeleton and some hints can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_beads(original_beads:dict, n_beads:int) -> dict:\n",
    "    \"\"\"\n",
    "    Samples n_beads beads from the original beads set\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_beads : dict\n",
    "        Dictionnary containing information on 2D and 3D position of the whole set of calibration beads\n",
    "    n_beads : int\n",
    "        Number of beads to select\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionnary containing information on 2D and 3D position of the subsampled of calibration beads\n",
    "    \"\"\"\n",
    "    output = deepcopy(original_beads) # ? First we deepcopy the original beads data, to avoid modifying it by mistake\n",
    "    selected_beads = []\n",
    "    \"\"\"\n",
    "    Let's modify our output until we reach the desired number of beads.\n",
    "    You want n beads sampled across both plates A & B (remember that plates C & D are just A & B rotated):\n",
    "    1. So you're gonna sample n_beads // 2 beads on plate A, and n_beads - (n_beads // 2) beads on plate B.\n",
    "    2. Add all these beads' names in the selected_beads list.\n",
    "    3. Then for each A & B bead, you want to add it's counterpart of plate C & D.\n",
    "    The selection step is already done :)\n",
    "    \"\"\"\n",
    "    all_beads = output['2d']['bead'].tolist()\n",
    "    plateA_beads = [bead for bead in all_beads if bead.startswith('A')]\n",
    "    plateB_beads = [bead for bead in all_beads if bead.startswith('B')]\n",
    "    selectedA_beads = random.sample(plateA_beads, n_beads//2)\n",
    "    selectedB_beads = random.sample(plateB_beads, n_beads - n_beads//2)\n",
    "    \n",
    "    corresponding_C_beads = [bead.replace('A', 'C', 1) for bead in selectedA_beads]\n",
    "    corresponding_D_beads = [bead.replace('B', 'D', 1) for bead in selectedB_beads]\n",
    "\n",
    "    selected_beads = selectedA_beads + selectedB_beads + corresponding_C_beads + corresponding_D_beads\n",
    "\n",
    "    output['2d'] = output['2d'][output['2d']['bead'].isin(selected_beads)].sort_values(by = 'bead', ignore_index = True)\n",
    "    output['3d'] = output['3d'][output['3d']['bead'].isin(selected_beads)].sort_values(by = 'bead', ignore_index = True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Let's increase the number of calibration beads gradually\n",
    "spine = spinetools.structures.Spine(os.path.join(root_directory,'Vertebrae2D.mat')) # Initialize the vertebrae structure\n",
    "\n",
    "# Create a dictionnary to store the results. Access a dictionnary key with brackets, for instance rms_measurements['x']\n",
    "rms_measurements = {\n",
    "        'x' : [],\n",
    "        'y' : [],\n",
    "        'z' : [],\n",
    "        '3d' : [],\n",
    "        'n_beads':[]\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "PSEUDOCODE\n",
    "computed_points_3d <- list\n",
    "for n_beads in [1...N], do:\n",
    "    beads_subset <- sample_n_beads(beads_data, n_beads)\n",
    "    A_view_0 <- get_a(view_0, beads_subset)\n",
    "    l_view_0 <- dlt(A_view_0)\n",
    "    A_view_1 <- get_a(view_1, beads_subset)\n",
    "    l_view_1 <- dlt(A_view_1)\n",
    "    for each vertebra in vertebrae:\n",
    "        for each anatomical_landmark in vertebra_points:\n",
    "        x_point, y_point, z_point <- calculate_3d_point(anatomical_landmark, l_view0, l_view1)\n",
    "        Append (x_point, y_point, z_point) to computed_points_3d\n",
    "    for each axis in ['x', ..., '3d']:\n",
    "        Append rms(SPINE_3D_POINTS, computed_points_3d) to rms_measurements[axis]\n",
    "        Append n_beads to rms_measurements['n_beads']\n",
    "\"\"\"\n",
    "\n",
    "max_beads = 22\n",
    "min_beads = 5\n",
    "for n_beads in range(max_beads, min_beads, -1):\n",
    "    beads_subset = sample_n_beads(beads_data, n_beads)\n",
    "    A_view_0 = get_a('Beads2D_'+view_0, beads_subset)\n",
    "    l_view_0 = spinetools.solver.dlt(A_view_0)\n",
    "    A_view_1 = get_a('Beads2D_'+view_1, beads_subset)\n",
    "    l_view_1 = spinetools.solver.dlt(A_view_1)\n",
    "\n",
    "    computed_points_3d = []\n",
    "\n",
    "    for _, v_name in enumerate(spine.vertebrae):\n",
    "        # TODO : for each vertebra, calculate the location of each anatomical landmark and add its x,y,z coordinates to vert_x, vert_y, vert_z. Each vertebra will then be added to the 3D plot and plotted in the end.\n",
    "        vert = spine.get(v_name).data # Returns the vertebra data\n",
    "         # for each anatomical_landmark in vertebra_points\n",
    "        for j, row in vert.iterrows():\n",
    "            # 2D PA0\n",
    "            u0, v0 = row['x_Vertebrae_PA0'], row['y_Vertebrae_PA0']\n",
    "            # 2D LAT\n",
    "            u1, v1 = row['x_Vertebrae_LAT'], row['y_Vertebrae_LAT']\n",
    "            x_point, y_point, z_point = calculate_3d_point(u0, v0, u1, v1, l_view_0, l_view_1)\n",
    "            computed_points_3d.append([x_point, y_point, z_point])\n",
    "\n",
    "    computed_points_3d = np.array(computed_points_3d)\n",
    "\n",
    "    rms_measurements['x'].append(rms(SPINE_3D_POINTS[:,0], computed_points_3d[:,0]))\n",
    "    rms_measurements['y'].append(rms(SPINE_3D_POINTS[:,1], computed_points_3d[:,1]))\n",
    "    rms_measurements['z'].append(rms(SPINE_3D_POINTS[:,2], computed_points_3d[:,2]))\n",
    "    rms_measurements['3d'].append(rms(SPINE_3D_POINTS, computed_points_3d))\n",
    "    rms_measurements['n_beads'].append(n_beads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly interlude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the number of beads and RMS values into numpy arrays for easier plotting\n",
    "n_beads = np.array(rms_measurements['n_beads'])\n",
    "rms_x = np.array(rms_measurements['x'])\n",
    "rms_y = np.array(rms_measurements['y'])\n",
    "rms_z = np.array(rms_measurements['z'])\n",
    "rms_3d = np.array(rms_measurements['3d'])\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for each RMS measurement\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n_beads,\n",
    "    y=rms_x,\n",
    "    mode='lines+markers',\n",
    "    name='RMS X',\n",
    "    line=dict(shape='spline'),\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n_beads,\n",
    "    y=rms_y,\n",
    "    mode='lines+markers',\n",
    "    name='RMS Y',\n",
    "    line=dict(shape='spline'),\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n_beads,\n",
    "    y=rms_z,\n",
    "    mode='lines+markers',\n",
    "    name='RMS Z',\n",
    "    line=dict(shape='spline'),\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=n_beads,\n",
    "    y=rms_3d,\n",
    "    mode='lines+markers',\n",
    "    name='RMS 3D',\n",
    "    line=dict(shape='spline'),\n",
    "))\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title='RMS Values vs. Number of Beads',\n",
    "    xaxis_title='Number of Beads',\n",
    "    yaxis_title='RMS Value',\n",
    "    legend=dict(title='RMS Metrics'),\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : On the same graph, plot all your RMS values wrt. the number of used calibration beads !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are 4 sets of 8 calibration beads. For each set, determine which one is which (same plate, small volume, medium volume, large volume) and plot calibration error curves.  \n",
    "Don't hesitate to use the function `plot_selected_beads` from `spinetools.render`to vizualize the selected beads to sort out the subsets !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_0 = ['A_1_6', 'A_4_6', 'A_1_2', 'A_4_2', 'B_1_5', 'B_5_5', 'B_1_1', 'B_5_1']\n",
    "set_1 = ['B_1_1', 'B_2_2', 'B_4_2', 'B_5_3', 'B_1_4', 'B_2_5', 'B_4_3', 'B_5_5']\n",
    "set_2 = ['A_1_4', 'A_2_4', 'A_1_5', 'A_2_5', 'B_1_3', 'B_2_3', 'B_1_4', 'B_2_4']\n",
    "set_3 = ['A_1_4', 'A_3_4', 'A_1_5', 'A_3_5', 'B_1_3', 'B_3_3', 'B_1_4', 'B_3_4']\n",
    "\n",
    "spinetools.render.plot_selected_beads(beads_data, set_0) # Large volume\n",
    "spinetools.render.plot_selected_beads(beads_data, set_1) # Same plate\n",
    "spinetools.render.plot_selected_beads(beads_data, set_2) # Small volume\n",
    "spinetools.render.plot_selected_beads(beads_data, set_3) # Medium volume\n",
    "\n",
    "large_volume, same_plate, small_volume, medium_volume = set_0, set_1, set_2, set_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : same thing as before, but now you have to select the provided beads ! Look at the function `sample_n_beads` from Q2.1 if you need some help on how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Calibration beads on the same plate:\n",
      "RMS x : 349.3594665527344\n",
      "RMS y : 51.47358703613281\n",
      "RMS z : 106.58932495117188\n",
      "RMS 3d : 368.86700439453125\n"
     ]
    }
   ],
   "source": [
    "# Re-order sets from small volume to large volume + same plate\n",
    "sets = [small_volume, medium_volume, large_volume, same_plate]\n",
    "set_names = ['Small volume', 'Medium volume', 'Large volume', 'Same plate']\n",
    "\n",
    "for i, set_ in enumerate(sets): \n",
    "    # Add counterparts to subsets\n",
    "    sets[i] += [bead.replace('A', 'C').replace('B', 'D') for bead in set_]\n",
    "\n",
    "    beads_set = deepcopy(beads_data)\n",
    "    \n",
    "    beads_set['2d'] = beads_set['2d'][beads_set['2d']['bead'].isin(sets[i])].sort_values(by='bead', ignore_index=True)\n",
    "    beads_set['3d'] = beads_set['3d'][beads_set['3d']['bead'].isin(sets[i])].sort_values(by='bead', ignore_index=True)\n",
    "    \n",
    "    # Assign the modified beads_set back to the original list\n",
    "    sets[i] = beads_set    \n",
    "\n",
    "rms_measurements = {\n",
    "        'x' : [],\n",
    "        'y' : [],\n",
    "        'z' : [],\n",
    "        '3d' : [],\n",
    "    }\n",
    "\n",
    "for i, beads_subset in enumerate(sets):\n",
    "    A_view_0 = get_a('Beads2D_'+view_0, beads_subset)\n",
    "    l_view_0 = spinetools.solver.dlt(A_view_0)\n",
    "    A_view_1 = get_a('Beads2D_'+view_1, beads_subset)\n",
    "    l_view_1 = spinetools.solver.dlt(A_view_1)\n",
    "\n",
    "    computed_points_3d = []\n",
    "\n",
    "    for _, v_name in enumerate(spine.vertebrae):\n",
    "        # TODO : for each vertebra, calculate the location of each anatomical landmark and add its x,y,z coordinates to vert_x, vert_y, vert_z. Each vertebra will then be added to the 3D plot and plotted in the end.\n",
    "        vert = spine.get(v_name).data # Returns the vertebra data\n",
    "         # for each anatomical_landmark in vertebra_points\n",
    "        for j, row in vert.iterrows():\n",
    "            # 2D PA0\n",
    "            u0, v0 = row['x_Vertebrae_PA0'], row['y_Vertebrae_PA0']\n",
    "            # 2D LAT\n",
    "            u1, v1 = row['x_Vertebrae_LAT'], row['y_Vertebrae_LAT']\n",
    "            x_point, y_point, z_point = calculate_3d_point(u0, v0, u1, v1, l_view_0, l_view_1)\n",
    "            computed_points_3d.append([x_point, y_point, z_point])\n",
    "\n",
    "    computed_points_3d = np.array(computed_points_3d)\n",
    "\n",
    "    rms_measurements['x'].append(rms(SPINE_3D_POINTS[:,0], computed_points_3d[:,0]))\n",
    "    rms_measurements['y'].append(rms(SPINE_3D_POINTS[:,1], computed_points_3d[:,1]))\n",
    "    rms_measurements['z'].append(rms(SPINE_3D_POINTS[:,2], computed_points_3d[:,2]))\n",
    "    rms_measurements['3d'].append(rms(SPINE_3D_POINTS, computed_points_3d))\n",
    "\n",
    "# Plotting\n",
    "fig = go.Figure()\n",
    "\n",
    "for axis in ['x', 'y', 'z', '3d']:\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=f'RMS {axis}',\n",
    "        x=set_names[:3],  # Subset names\n",
    "        y=rms_measurements[axis],  # RMS values for the current axis\n",
    "        text=[f'{v:.4f}' for v in rms_measurements[axis]],  # Add text labels\n",
    "        textposition='auto'\n",
    "    ))\n",
    "\n",
    "# Update the layout of the plot\n",
    "fig.update_layout(\n",
    "    title=\"Calibration Errors (RMS) for Each Subset\",\n",
    "    barmode='group',  # Group bars for each category\n",
    "    xaxis_title=\"Subsets\",\n",
    "    yaxis_title=\"RMS Error\",\n",
    "    legend_title=\"Axes\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# RMS for calibration beads on the same plate\n",
    "print(f'Calibration beads on the same plate:')\n",
    "for axis, values in rms_measurements.items():\n",
    "    print(f'RMS {axis} : {values[3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **small** calibration volume from previous question, plot reconstruction error with respect to the center of gravity of the calibration volume !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center Of Gravity small volume subset: [-256.91019375, 45.61763124999999, -20.857125000000003]\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "small_volume_subset = sets[0]\n",
    "\n",
    "def calculate_COG(beads_set:dict):\n",
    "    cog_x = beads_set['3d']['x_3d'].mean()\n",
    "    cog_y = beads_set['3d']['y_3d'].mean()\n",
    "    cog_z = beads_set['3d']['z_3d'].mean()\n",
    "    return [cog_x, cog_y, cog_z]\n",
    "\n",
    "def distance_between(p1, p2):\n",
    "    return np.sqrt( (p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2 )\n",
    "\n",
    "COG = calculate_COG(small_volume_subset)\n",
    "print(f'Center Of Gravity small volume subset: {COG}')\n",
    "\n",
    "errors = {\n",
    "    'x' : [],\n",
    "    'y' : [],\n",
    "    'z' : [],\n",
    "    '3d' : [],\n",
    "    'distance_to_cog' : []\n",
    "}\n",
    "\n",
    "A_view_0 = get_a('Beads2D_'+view_0, small_volume_subset)\n",
    "l_view_0 = spinetools.solver.dlt(A_view_0)\n",
    "A_view_1 = get_a('Beads2D_'+view_1, small_volume_subset)\n",
    "l_view_1 = spinetools.solver.dlt(A_view_1)\n",
    "\n",
    "computed_points_3d = []\n",
    "\n",
    "for i, v_name in enumerate(spine.vertebrae):\n",
    "    # TODO : for each vertebra, calculate the location of each anatomical landmark and add its x,y,z coordinates to vert_x, vert_y, vert_z. Each vertebra will then be added to the 3D plot and plotted in the end.\n",
    "    vert = spine.get(v_name).data # Returns the vertebra data\n",
    "        # for each anatomical_landmark in vertebra_points\n",
    "    for j, row in vert.iterrows():\n",
    "        # 2D PA0\n",
    "        u0, v0 = row['x_Vertebrae_PA0'], row['y_Vertebrae_PA0']\n",
    "        # 2D LAT\n",
    "        u1, v1 = row['x_Vertebrae_LAT'], row['y_Vertebrae_LAT']\n",
    "        x_point, y_point, z_point = calculate_3d_point(u0, v0, u1, v1, l_view_0, l_view_1)\n",
    "        computed_points_3d.append([x_point, y_point, z_point])\n",
    "\n",
    "        errors['x'].append(abs(SPINE_3D_POINTS[i][0] - x_point))\n",
    "        errors['y'].append(abs(SPINE_3D_POINTS[i][1] - y_point))\n",
    "        errors['z'].append(abs(SPINE_3D_POINTS[i][2] - z_point))\n",
    "        errors['3d'].append(distance_between(SPINE_3D_POINTS[i], [x_point, y_point, z_point]))\n",
    "        errors['distance_to_cog'].append(distance_between(SPINE_3D_POINTS[i], COG))\n",
    "\n",
    "computed_points_3d = np.array(computed_points_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center Of Gravity small volume subset: [-256.91019375, 45.61763124999999, -20.857125000000003]\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n",
      "Index(['bead', 'x_2d', 'y_2d', 'x_3d', 'y_3d', 'z_3d'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "small_volume_subset = sets[0]\n",
    "\n",
    "def calculate_COG(beads_set:dict):\n",
    "    cog_x = beads_set['3d']['x_3d'].mean()\n",
    "    cog_y = beads_set['3d']['y_3d'].mean()\n",
    "    cog_z = beads_set['3d']['z_3d'].mean()\n",
    "    return [cog_x, cog_y, cog_z]\n",
    "\n",
    "def distance_between(p1, p2):\n",
    "    return np.sqrt( (p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2 )\n",
    "\n",
    "COG = calculate_COG(small_volume_subset)\n",
    "print(f'Center Of Gravity small volume subset: {COG}')\n",
    "\n",
    "errors = {\n",
    "    'x' : [],\n",
    "    'y' : [],\n",
    "    'z' : [],\n",
    "    '3d' : [],\n",
    "    'distance_to_cog' : []\n",
    "}\n",
    "\n",
    "A_view_0 = get_a('Beads2D_'+view_0, small_volume_subset)\n",
    "l_view_0 = spinetools.solver.dlt(A_view_0)\n",
    "A_view_1 = get_a('Beads2D_'+view_1, small_volume_subset)\n",
    "l_view_1 = spinetools.solver.dlt(A_view_1)\n",
    "\n",
    "computed_points_3d = []\n",
    "\n",
    "for i, v_name in enumerate(spine.vertebrae):\n",
    "    # TODO : for each vertebra, calculate the location of each anatomical landmark and add its x,y,z coordinates to vert_x, vert_y, vert_z. Each vertebra will then be added to the 3D plot and plotted in the end.\n",
    "    vert = spine.get(v_name).data # Returns the vertebra data\n",
    "        # for each anatomical_landmark in vertebra_points\n",
    "    for j, row in vert.iterrows():\n",
    "        # 2D PA0\n",
    "        u0, v0 = row['x_Vertebrae_PA0'], row['y_Vertebrae_PA0']\n",
    "        # 2D LAT\n",
    "        u1, v1 = row['x_Vertebrae_LAT'], row['y_Vertebrae_LAT']\n",
    "        x_point, y_point, z_point = calculate_3d_point(u0, v0, u1, v1, l_view_0, l_view_1)\n",
    "        computed_points_3d.append([x_point, y_point, z_point])\n",
    "\n",
    "        point_number = i*6+j    # 6 points for each vertebra \n",
    "\n",
    "        errors['x'].append(abs(SPINE_3D_POINTS[i*6+j][0] - x_point))\n",
    "        errors['y'].append(abs(SPINE_3D_POINTS[i*6+j][1] - y_point))\n",
    "        errors['z'].append(abs(SPINE_3D_POINTS[i*6+j][2] - z_point))\n",
    "        errors['3d'].append(distance_between(SPINE_3D_POINTS[i*6+j], [x_point, y_point, z_point]))\n",
    "        errors['distance_to_cog'].append(distance_between(SPINE_3D_POINTS[i*6+j], COG))\n",
    "\n",
    "computed_points_3d = np.array(computed_points_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you have to code the function that allow us to add noise to the calibration beads coordinates. Hint : you should take a look at the documentation of `np.random.normal` :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_2d(original_beads:dict, std:float) -> dict:\n",
    "    \"\"\"\n",
    "    Adds noise to the 2D coordinates of the beads\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_beads : dict\n",
    "        Dictionnary containing information on 2D and 3D position of the a set of calibration beads\n",
    "    std : float\n",
    "        Standard deviation for the noise added.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Noised beads set\n",
    "    \"\"\"\n",
    "    output = deepcopy(original_beads) # ? First we deepcopy the original beads data, to avoid modifying it by mistake\n",
    "    # TODO : select 2D beads and add noise to them\n",
    "    for bead in output['2d']:\n",
    "        bead['x_2d'] += np.random.normal(0, std)  # Add noise to x_2d coordinate\n",
    "        bead['y_2d'] += np.random.normal(0, std)  # Add noise to y_2d coordinate\n",
    "    return output\n",
    "\n",
    "def add_noise_3d(original_beads:dict, std:float) -> dict:\n",
    "    \"\"\"\n",
    "    Adds noise to the 3D coordinates of the beads\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_beads : dict\n",
    "        Dictionnary containing information on 2D and 3D position of the a set of calibration beads\n",
    "    std : float\n",
    "        Standard deviation for the noise added.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Noised beads set\n",
    "    \"\"\"\n",
    "    output = deepcopy(original_beads) # ? First we deepcopy the original beads data, to avoid modifying it by mistake\n",
    "    # TODO : select 3D beads and add noise to them\n",
    "    for bead in output['3d']:\n",
    "        bead['x_3d'] += np.random.normal(0, std)  # Add noise to x_3d coordinate\n",
    "        bead['y_3d'] += np.random.normal(0, std)  # Add noise to y_3d coordinate\n",
    "        bead['z_3d'] += np.random.normal(0, std)  # Add noise to z_3d coordinate\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question is a bit tricky, as you have to get measurements for couples of values of standard deviation for 2D and 3D noise. A line plot is not very adapted for this, but we could use a heatmap ! Here is a small example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "heatmap = np.random.rand(11, 11)\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z = heatmap,\n",
    "        x = np.linspace(0., 10., 11),\n",
    "        y = np.linspace(0., 10., 11),\n",
    "        text = heatmap.round(2),\n",
    "        texttemplate=\"%{text}\",\n",
    "        colorscale='turbo'\n",
    "    ))\n",
    "fig.update_xaxes(title_text='Axis 1')\n",
    "fig.update_yaxes(title_text='Axis 2')\n",
    "fig.update_layout(title = 'Plot title')\n",
    "fig.update_traces(showscale=False)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbm6700e_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
